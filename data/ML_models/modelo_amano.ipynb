{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (1.0.3)\n",
      "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.6/dist-packages (from pandas) (2.8.1)\n",
      "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas) (2019.3)\n",
      "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.6/dist-packages (from pandas) (1.18.2)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.6.1->pandas) (1.14.0)\n",
      "Requirement already satisfied: sklearn in /usr/local/lib/python3.6/dist-packages (0.0)\n",
      "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (from sklearn) (0.22.2.post1)\n",
      "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->sklearn) (0.14.1)\n",
      "Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->sklearn) (1.4.1)\n",
      "Requirement already satisfied: numpy>=1.11.0 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->sklearn) (1.18.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas \n",
    "!pip install sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os,datetime\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorboard import notebook\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 39), started 1:00:15 ago. (Use '!kill 39' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-e0e0e8efb1ee3e95\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-e0e0e8efb1ee3e95\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          url.port = 6006;\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "###---< Enable Tensorboard in port 6666 >---###\n",
    "%load_ext tensorboard\n",
    "log_dir=\"/tf/logs\"\n",
    "%tensorboard --logdir {log_dir} --bind_all   #always --bind_all\n",
    "callback=tf.keras.callbacks.TensorBoard(log_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Known TensorBoard instances:\n",
      "  - port 6006: logdir /tf/logs (started 0:34:48 ago; pid 39)\n"
     ]
    }
   ],
   "source": [
    "notebook.list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/download.tensorflow.org/data/iris_training.csv\n",
      "8192/2194 [================================================================================================================] - 0s 0us/step\n",
      "Local copy of the dataset file: /root/.keras/datasets/iris_training.csv\n"
     ]
    }
   ],
   "source": [
    "train_dataset_url = \"https://storage.googleapis.com/download.tensorflow.org/data/iris_training.csv\"\n",
    "\n",
    "train_dataset_fp = tf.keras.utils.get_file(fname=os.path.basename(train_dataset_url),\n",
    "                                           origin=train_dataset_url)\n",
    "\n",
    "print(\"Local copy of the dataset file: {}\".format(train_dataset_fp))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features: ['sepal_length', 'sepal_width', 'petal_length', 'petal_width']\n",
      "Label: species\n"
     ]
    }
   ],
   "source": [
    "column_names = ['sepal_length', 'sepal_width', 'petal_length', 'petal_width', 'species']\n",
    "\n",
    "feature_names = column_names[:-1]\n",
    "label_name = column_names[-1]\n",
    "\n",
    "print(\"Features: {}\".format(feature_names))\n",
    "print(\"Label: {}\".format(label_name))\n",
    "\n",
    "class_names = ['Iris setosa', 'Iris versicolor', 'Iris virginica']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "\n",
    "train_dataset = tf.data.experimental.make_csv_dataset(\n",
    "    train_dataset_fp,\n",
    "    batch_size,\n",
    "    column_names=column_names,\n",
    "    label_name=label_name,\n",
    "    num_epochs=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict([('sepal_length', <tf.Tensor: shape=(32,), dtype=float32, numpy=\n",
      "array([6.6, 6.3, 7. , 6.7, 7.7, 6.1, 6.7, 6.1, 7.3, 6.7, 4.4, 5.4, 5.1,\n",
      "       5.6, 5.8, 5.4, 5.4, 6.4, 7.7, 7.7, 5.9, 6.2, 5. , 6.7, 6.5, 5.9,\n",
      "       6.3, 4.6, 5.8, 5.8, 7.7, 6.5], dtype=float32)>), ('sepal_width', <tf.Tensor: shape=(32,), dtype=float32, numpy=\n",
      "array([2.9, 2.5, 3.2, 3.3, 2.8, 2.8, 3. , 3. , 2.9, 3.1, 3.2, 3.9, 3.5,\n",
      "       2.7, 2.7, 3.7, 3.9, 2.7, 2.6, 3.8, 3.2, 2.2, 2. , 3.1, 3. , 3. ,\n",
      "       3.3, 3.4, 2.6, 2.7, 3. , 3. ], dtype=float32)>), ('petal_length', <tf.Tensor: shape=(32,), dtype=float32, numpy=\n",
      "array([4.6, 5. , 4.7, 5.7, 6.7, 4.7, 5. , 4.9, 6.3, 5.6, 1.3, 1.3, 1.4,\n",
      "       4.2, 4.1, 1.5, 1.7, 5.3, 6.9, 6.7, 4.8, 4.5, 3.5, 4.4, 5.2, 5.1,\n",
      "       4.7, 1.4, 4. , 5.1, 6.1, 5.8], dtype=float32)>), ('petal_width', <tf.Tensor: shape=(32,), dtype=float32, numpy=\n",
      "array([1.3, 1.9, 1.4, 2.1, 2. , 1.2, 1.7, 1.8, 1.8, 2.4, 0.2, 0.4, 0.3,\n",
      "       1.3, 1. , 0.2, 0.4, 1.9, 2.3, 2.2, 1.8, 1.5, 1. , 1.4, 2. , 1.8,\n",
      "       1.6, 0.3, 1.2, 1.9, 2.3, 2.2], dtype=float32)>)])\n"
     ]
    }
   ],
   "source": [
    "features, labels = next(iter(train_dataset))\n",
    "\n",
    "print(features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pack_features_vector(features, labels):\n",
    "  \"\"\"Pack the features into a single array.\"\"\"\n",
    "  features = tf.stack(list(features.values()), axis=1)\n",
    "  return features, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = train_dataset.map(pack_features_vector)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[5.  3.5 1.6 0.6]\n",
      " [6.9 3.2 5.7 2.3]\n",
      " [4.8 3.  1.4 0.1]\n",
      " [5.8 2.7 5.1 1.9]\n",
      " [7.2 3.2 6.  1.8]], shape=(5, 4), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "features, labels = next(iter(train_dataset))\n",
    "\n",
    "print(features[:5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model():\n",
    "    model = tf.keras.Sequential([\n",
    "      tf.keras.layers.Dense(10, activation=tf.nn.relu, input_shape=(4,)),  # input shape required\n",
    "      tf.keras.layers.Dense(10, activation=tf.nn.relu),\n",
    "      tf.keras.layers.Dense(3)\n",
    "    ])\n",
    "    return model\n",
    "model = create_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(5, 3), dtype=float32, numpy=\n",
       "array([[-0.6698812 ,  3.0292413 ,  1.4628589 ],\n",
       "       [-0.29717648,  5.807516  ,  3.1580958 ],\n",
       "       [-0.5405931 ,  2.6424017 ,  1.2552483 ],\n",
       "       [-0.15525007,  4.935645  ,  2.7362504 ],\n",
       "       [-0.13413274,  5.8003983 ,  3.1542149 ]], dtype=float32)>"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = model(features)\n",
    "predictions[:5]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(5, 3), dtype=float32, numpy=\n",
       "array([[0.02006027, 0.8106721 , 0.16926765],\n",
       "       [0.00208064, 0.93203205, 0.06588738],\n",
       "       [0.03210951, 0.77444535, 0.19344509],\n",
       "       [0.00550795, 0.8952369 , 0.09925514],\n",
       "       [0.00246511, 0.9314735 , 0.06606138]], dtype=float32)>"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.nn.softmax(predictions[:5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: [1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "    Labels: [0 2 0 2 2 0 0 0 1 0 2 1 1 0 2 2 0 2 0 0 1 0 2 2 0 0 1 0 1 2 1 0]\n"
     ]
    }
   ],
   "source": [
    "print(\"Prediction: {}\".format(tf.argmax(predictions, axis=1)))\n",
    "print(\"    Labels: {}\".format(labels))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss test: 2.5883514881134033\n"
     ]
    }
   ],
   "source": [
    "def loss(model, x, y, training):\n",
    "  # training=training is needed only if there are layers with different\n",
    "  # behavior during training versus inference (e.g. Dropout).\n",
    "  y_ = model(x, training=training)\n",
    "\n",
    "  return loss_object(y_true=y, y_pred=y_)\n",
    "\n",
    "l = loss(model, features, labels, training=False)\n",
    "print(\"Loss test: {}\".format(l))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grad(model, inputs, targets):\n",
    "  with tf.GradientTape() as tape:\n",
    "    loss_value = loss(model, inputs, targets, training=True)\n",
    "  return loss_value, tape.gradient(loss_value, model.trainable_variables)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 0, Initial Loss: 2.5883514881134033\n",
      "Step: 1,         Loss: 2.0027570724487305\n"
     ]
    }
   ],
   "source": [
    "optimizer = tf.keras.optimizers.SGD(learning_rate=0.01)\n",
    "\n",
    "loss_value, grads = grad(model, features, labels)\n",
    "\n",
    "print(\"Step: {}, Initial Loss: {}\".format(optimizer.iterations.numpy(),\n",
    "                                          loss_value.numpy()))\n",
    "\n",
    "optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
    "\n",
    "print(\"Step: {},         Loss: {}\".format(optimizer.iterations.numpy(),\n",
    "                                          loss(model, features, labels, training=True).numpy()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 000: Loss: 1.448, Accuracy: 37.500%\n",
      "Epoch 050: Loss: 0.749, Accuracy: 74.167%\n",
      "Epoch 100: Loss: 0.487, Accuracy: 86.667%\n",
      "Epoch 150: Loss: 0.298, Accuracy: 95.833%\n",
      "Epoch 200: Loss: 0.215, Accuracy: 96.667%\n"
     ]
    }
   ],
   "source": [
    "## Note: Rerunning this cell uses the same model variables\n",
    "\n",
    "# Keep results for plotting\n",
    "train_loss_results = []\n",
    "train_accuracy_results = []\n",
    "\n",
    "num_epochs = 201\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "  epoch_loss_avg = tf.keras.metrics.Mean()\n",
    "  epoch_accuracy = tf.keras.metrics.SparseCategoricalAccuracy()\n",
    "\n",
    "  # Training loop - using batches of 32\n",
    "  for x, y in train_dataset:\n",
    "    # Optimize the model\n",
    "    loss_value, grads = grad(model, x, y)\n",
    "    optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
    "\n",
    "    # Track progress\n",
    "    epoch_loss_avg.update_state(loss_value)  # Add current batch loss\n",
    "    # Compare predicted label to actual label\n",
    "    # training=True is needed only if there are layers with different\n",
    "    # behavior during training versus inference (e.g. Dropout).\n",
    "    epoch_accuracy.update_state(y, model(x, training=True))\n",
    "\n",
    "  # End epoch\n",
    "  train_loss_results.append(epoch_loss_avg.result())\n",
    "  train_accuracy_results.append(epoch_accuracy.result())\n",
    "\n",
    "  if epoch % 50 == 0:\n",
    "    print(\"Epoch {:03d}: Loss: {:.3f}, Accuracy: {:.3%}\".format(epoch,\n",
    "                                                                epoch_loss_avg.result(),\n",
    "                                                                epoch_accuracy.result()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
